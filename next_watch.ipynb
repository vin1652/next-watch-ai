{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe9190ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: firecrawl-py in c:\\users\\vinay\\anaconda3\\lib\\site-packages (4.14.1)\n",
      "Requirement already satisfied: groq in c:\\users\\vinay\\anaconda3\\lib\\site-packages (0.30.0)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\vinay\\anaconda3\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\vinay\\anaconda3\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\vinay\\anaconda3\\lib\\site-packages (4.11.1)\n",
      "Requirement already satisfied: lxml in c:\\users\\vinay\\anaconda3\\lib\\site-packages (4.9.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from firecrawl-py) (3.9.3)\n",
      "Requirement already satisfied: httpx in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from firecrawl-py) (0.28.1)\n",
      "Requirement already satisfied: requests in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from firecrawl-py) (2.32.5)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from firecrawl-py) (1.6.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from firecrawl-py) (2.11.2)\n",
      "Requirement already satisfied: websockets in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from firecrawl-py) (15.0.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from groq) (4.12.2)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from groq) (1.9.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from groq) (4.9.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from groq) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.3.2.post1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->groq) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->groq) (3.4)\n",
      "Requirement already satisfied: certifi in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from httpx->firecrawl-py) (2023.7.22)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from httpx->firecrawl-py) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx->firecrawl-py) (0.14.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from pydantic>=2.0->firecrawl-py) (0.4.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from pydantic>=2.0->firecrawl-py) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from pydantic>=2.0->firecrawl-py) (2.33.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from aiohttp->firecrawl-py) (6.0.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from aiohttp->firecrawl-py) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from aiohttp->firecrawl-py) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from aiohttp->firecrawl-py) (1.4.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from aiohttp->firecrawl-py) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from aiohttp->firecrawl-py) (1.9.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from requests->firecrawl-py) (1.26.14)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\vinay\\anaconda3\\lib\\site-packages (from requests->firecrawl-py) (2.0.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\vinay\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\vinay\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\vinay\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\vinay\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\vinay\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\vinay\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 0) INSTALLS (run once)\n",
    "# ============================================================\n",
    "!pip install firecrawl-py groq python-dotenv tqdm beautifulsoup4 lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a96b89c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Firecrawl key loaded: True\n",
      "Groq key loaded: True\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 1) SETUP: ENV + CLIENTS\n",
    "# ============================================================\n",
    "import os, re, json, ast\n",
    "from typing import Any, Dict, List\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "FIRECRAWL_API_KEY = os.getenv(\"FIRECRAWL_API_KEY\")\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "print(\"Firecrawl key loaded:\", bool(FIRECRAWL_API_KEY))\n",
    "print(\"Groq key loaded:\", bool(GROQ_API_KEY))\n",
    "\n",
    "from groq import Groq\n",
    "groq_client = Groq(api_key=GROQ_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5bd9e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a Groq model. If rate-limited, try llama-3.1-70b-versatile\n",
    "MODEL = \"llama-3.3-70b-versatile\"\n",
    "\n",
    "from firecrawl import FirecrawlApp\n",
    "firecrawl = FirecrawlApp(api_key=FIRECRAWL_API_KEY)\n",
    "\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc4eee19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 2) GENERIC HELPERS\n",
    "# ============================================================\n",
    "\n",
    "def groq_chat(prompt: str, model: str = MODEL, temperature: float = 0.2) -> str:\n",
    "    \"\"\"Small wrapper for Groq chat.\"\"\"\n",
    "    resp = groq_client.chat.completions.create(\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    )\n",
    "    return resp.choices[0].message.content\n",
    "\n",
    "def extract_first_json(text: str) -> Dict[str, Any]:\n",
    "    \"\"\"Extract JSON object from model output (even if wrapped with extra text).\"\"\"\n",
    "    text = text.strip()\n",
    "    try:\n",
    "        return json.loads(text)\n",
    "    except:\n",
    "        pass\n",
    "    m = re.search(r\"\\{.*\\}\", text, flags=re.DOTALL)\n",
    "    if not m:\n",
    "        raise ValueError(\"Could not extract JSON from model output.\")\n",
    "    return json.loads(m.group(0))\n",
    "\n",
    "def parse_url_list(model_text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Parse a Python list of URLs from model output.\n",
    "    Handles fenced blocks like ```python ... ``` and other extra text.\n",
    "    Uses ast.literal_eval (safe).\n",
    "    \"\"\"\n",
    "    s = model_text.strip()\n",
    "    s = re.sub(r\"^```(?:python)?\\s*\", \"\", s)\n",
    "    s = re.sub(r\"\\s*```$\", \"\", s)\n",
    "\n",
    "    m = re.search(r\"\\[.*\\]\", s, flags=re.DOTALL)\n",
    "    if m:\n",
    "        s = m.group(0)\n",
    "\n",
    "    try:\n",
    "        data = ast.literal_eval(s)\n",
    "        if isinstance(data, list):\n",
    "            return [u.strip() for u in data if isinstance(u, str) and u.strip().startswith(\"http\")]\n",
    "    except Exception as e:\n",
    "        print(\"parse_url_list failed:\", e)\n",
    "        print(\"raw sample:\", model_text[:400])\n",
    "    return []\n",
    "\n",
    "# Firecrawl v2 Document/dict extractors\n",
    "def extract_markdown(scrape_result) -> str:\n",
    "    if scrape_result is None:\n",
    "        return \"\"\n",
    "    if hasattr(scrape_result, \"markdown\") and scrape_result.markdown:\n",
    "        return scrape_result.markdown\n",
    "    if isinstance(scrape_result, dict):\n",
    "        return scrape_result.get(\"markdown\", \"\") or \"\"\n",
    "    if hasattr(scrape_result, \"data\"):\n",
    "        data = scrape_result.data\n",
    "        if isinstance(data, dict):\n",
    "            return data.get(\"markdown\", \"\") or \"\"\n",
    "        if hasattr(data, \"markdown\"):\n",
    "            return data.markdown or \"\"\n",
    "    return \"\"\n",
    "\n",
    "def extract_html(scrape_result) -> str:\n",
    "    if scrape_result is None:\n",
    "        return \"\"\n",
    "    if hasattr(scrape_result, \"html\") and scrape_result.html:\n",
    "        return scrape_result.html\n",
    "    if isinstance(scrape_result, dict):\n",
    "        return scrape_result.get(\"html\", \"\") or \"\"\n",
    "    if hasattr(scrape_result, \"data\"):\n",
    "        data = scrape_result.data\n",
    "        if isinstance(data, dict):\n",
    "            return data.get(\"html\", \"\") or \"\"\n",
    "        if hasattr(data, \"html\"):\n",
    "            return data.html or \"\"\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7c71e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 3) URL GENERATORS (Groq)\n",
    "#    - avoids Firecrawl search credits entirely\n",
    "# ============================================================\n",
    "\n",
    "def generate_movie_urls(movie_name: str, max_urls: int = 5) -> List[str]:\n",
    "    \"\"\"\n",
    "    Generate URLs to research a movie (wiki + analysis pages).\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "You are gathering research sources for film analysis.\n",
    "\n",
    "Movie: {movie_name}\n",
    "\n",
    "Return up to {max_urls} high-quality URLs:\n",
    "- Wikipedia page (preferably)\n",
    "- 2â€“3 analysis/review pages\n",
    "- avoid streaming links\n",
    "- avoid spam\n",
    "\n",
    "Return ONLY a Python list of URLs.\n",
    "\"\"\"\n",
    "    out = groq_chat(prompt, temperature=0)\n",
    "    return parse_url_list(out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48af6a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 4) SCRAPING FUNCTIONS (Firecrawl v2)\n",
    "# ============================================================\n",
    "\n",
    "def scrape_urls_to_bundle(urls: List[str], max_pages: int = 3, per_source_chars: int = 2500, total_chars: int = 9000) -> str:\n",
    "    \"\"\"\n",
    "    Scrape up to max_pages URLs and return a condensed bundle (markdown).\n",
    "    Used for seed movie research.\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    for url in urls[:max_pages]:\n",
    "        try:\n",
    "            res = firecrawl.scrape(url=url, formats=[\"markdown\"])\n",
    "            md = extract_markdown(res)\n",
    "            if not md:\n",
    "                continue\n",
    "            chunks.append(f\"SOURCE: {url}\\n{md[:per_source_chars]}\")\n",
    "        except Exception as e:\n",
    "            print(\"Scrape error:\", url, e)\n",
    "    bundle = \"\\n\\n\".join(chunks)\n",
    "    return bundle[:total_chars]\n",
    "\n",
    "def research_movie(movie: str, max_pages: int = 3) -> str:\n",
    "    \"\"\"\n",
    "    Movie research: Groq â†’ URLs â†’ Firecrawl scrape â†’ text bundle.\n",
    "    \"\"\"\n",
    "    print(f\"\\nðŸŽ¬ Researching: {movie}\")\n",
    "    urls = generate_movie_urls(movie, max_urls=5)\n",
    "    print(\"URLs found:\", len(urls))\n",
    "    for u in urls[:max_pages]:\n",
    "        print(\" -\", u)\n",
    "\n",
    "    if not urls:\n",
    "        return \"\"\n",
    "    text = scrape_urls_to_bundle(urls, max_pages=max_pages)\n",
    "    print(\"Research length:\", len(text))\n",
    "    return text\n",
    "\n",
    "def research_movies(movie_list: List[str], max_pages_per_movie: int = 3) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Research multiple movies. Always returns dict {movie: text}.\n",
    "    \"\"\"\n",
    "    out: Dict[str, str] = {}\n",
    "    for m in tqdm(movie_list):\n",
    "        out[m] = research_movie(m, max_pages=max_pages_per_movie)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a96daedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 5) SEED MOVIE FINGERPRINT AGENT (Groq)\n",
    "# ============================================================\n",
    "\n",
    "FINGERPRINT_SCHEMA_HINT = \"\"\"\n",
    "Return ONLY JSON with these keys:\n",
    "\n",
    "authorship_voice: {\n",
    "  director_style: [strings],\n",
    "  screenwriter_style: [strings],\n",
    "  cinematography_style: [strings],\n",
    "  editing_style: [strings]\n",
    "},\n",
    "\n",
    "narrative_architecture: {\n",
    "  structure_type: string,\n",
    "  inciting_incident_timing: \"early\"|\"mid\"|\"late\"|null,\n",
    "  pacing: \"slow\"|\"moderate\"|\"fast\"|null,\n",
    "  ending_type: \"ambiguous\"|\"resolved\"|\"ironic\"|\"circular\"|null,\n",
    "  conflict_type: \"internal\"|\"external\"|\"mixed\"|null\n",
    "},\n",
    "\n",
    "themes_subtext: {\n",
    "  primary_themes: [strings],\n",
    "  motifs: [strings],\n",
    "  worldview: \"bleak\"|\"hopeful\"|\"mixed\"|null,\n",
    "  moral_stance: \"compassionate\"|\"cynical\"|\"neutral\"|null\n",
    "},\n",
    "\n",
    "style_tone: {\n",
    "  realism_vs_stylized: number,            // 0.0 to 1.0\n",
    "  humor_style: \"none\"|\"deadpan\"|\"dark\"|\"broad\"|null,\n",
    "  dread_style: \"psychological\"|\"cosmic\"|\"social\"|\"bodily\"|null,\n",
    "  performance_style: \"naturalistic\"|\"theatrical\"|null\n",
    "},\n",
    "\n",
    "extras: {\n",
    "  dialogue_density: \"low\"|\"med\"|\"high\"|null,\n",
    "  narrative_mode: \"linear\"|\"nonlinear\"|\"elliptical\"|null,\n",
    "  intensity_curve: \"gradual\"|\"spiky\"|\"constant\"|null\n",
    "},\n",
    "\n",
    "confidence: {\n",
    "  overall: number,                        // 0.0 to 1.0\n",
    "  low_confidence_fields: [strings]\n",
    "},\n",
    "\n",
    "non_spoiler_notes: [strings]              // 2â€“5 bullets, NO plot spoilers\n",
    "\"\"\"\n",
    "\n",
    "def fingerprint_movie(movie_title: str, research_text: str) -> Dict[str, Any]:\n",
    "    prompt = f\"\"\"\n",
    "You are a film student and critic. Analyze the film's craft and storytelling style.\n",
    "IMPORTANT:\n",
    "- Do NOT include spoilers.\n",
    "- Do NOT describe specific plot events, twists, or the ending.\n",
    "- You MAY label ending_type but do NOT explain what happens.\n",
    "\n",
    "Movie: {movie_title}\n",
    "\n",
    "Evidence (web excerpts):\n",
    "{research_text}\n",
    "\n",
    "{FINGERPRINT_SCHEMA_HINT}\n",
    "\n",
    "ONLY output JSON.\n",
    "\"\"\"\n",
    "    out = groq_chat(prompt, temperature=0.2)\n",
    "    return extract_first_json(out)\n",
    "\n",
    "def fingerprint_seed_movies(seed_movies: List[str], research_data: Dict[str, str]) -> Dict[str, Dict[str, Any]]:\n",
    "    fps: Dict[str, Dict[str, Any]] = {}\n",
    "    for m in tqdm(seed_movies):\n",
    "        txt = research_data.get(m, \"\")\n",
    "        if not isinstance(txt, str):\n",
    "            txt = str(txt)\n",
    "        if len(txt.strip()) < 500:\n",
    "            print(f\"âš ï¸ Skipping {m}: not enough research text ({len(txt)} chars)\")\n",
    "            continue\n",
    "        fps[m] = fingerprint_movie(m, txt)\n",
    "    return fps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfd68651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 6) TASTE PROFILER AGENT (Groq)\n",
    "# ============================================================\n",
    "\n",
    "TASTE_SCHEMA_HINT = \"\"\"\n",
    "Return ONLY JSON with keys:\n",
    "\n",
    "taste_summary: string,\n",
    "core_signals: [strings],\n",
    "secondary_signals: [strings],\n",
    "avoid_signals: [strings],\n",
    "query_pack: {\n",
    "  anchors: [strings],\n",
    "  must_have: [strings],\n",
    "  should_have: [strings],\n",
    "  avoid: [strings]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "def taste_profiler(seed_fingerprints: Dict[str, Dict[str, Any]]) -> Dict[str, Any]:\n",
    "    prompt = f\"\"\"\n",
    "You are a film student building a taste profile from the provided films.\n",
    "Infer what the viewer consistently likes in:\n",
    "- authorship/voice\n",
    "- narrative architecture\n",
    "- themes/subtext\n",
    "- style/tone\n",
    "\n",
    "Fingerprints (JSON per movie):\n",
    "{json.dumps(seed_fingerprints, ensure_ascii=False)[:14000]}\n",
    "\n",
    "{TASTE_SCHEMA_HINT}\n",
    "\n",
    "ONLY output JSON.\n",
    "\"\"\"\n",
    "    out = groq_chat(prompt, temperature=0.2)\n",
    "    return extract_first_json(out)\n",
    "\n",
    "def build_search_query(taste_profile: Dict[str, Any]) -> str:\n",
    "    qp = taste_profile.get(\"query_pack\", {}) or {}\n",
    "    anchors = qp.get(\"anchors\", []) or []\n",
    "    must = qp.get(\"must_have\", []) or []\n",
    "    should = qp.get(\"should_have\", []) or []\n",
    "    avoid = qp.get(\"avoid\", []) or []\n",
    "\n",
    "    anchor_part = \" and \".join(anchors[:2]) if anchors else \"\"\n",
    "    must_part = \" \".join([f'\"{x}\"' for x in must[:4]])\n",
    "    should_part = \" \".join([f'\"{x}\"' for x in should[:2]])\n",
    "    avoid_part = \" \".join([f'-\"{x}\"' for x in avoid[:3]])\n",
    "\n",
    "    query = f\"movies like {anchor_part} {must_part} {should_part} {avoid_part}\".strip()\n",
    "    return re.sub(r\"\\s+\", \" \", query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd04e9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 7) CANDIDATE EXTRACTION (HTML parsing + LLM cleaning)\n",
    "# ============================================================\n",
    "\n",
    "\n",
    "\n",
    "DIRECT_CANDIDATES_SCHEMA = \"\"\"\n",
    "Return ONLY JSON with:\n",
    "titles: [strings]  // 30 movie titles\n",
    "\"\"\"\n",
    "\n",
    "def propose_candidates_directly(taste_profile: dict, seed_movies: List[str], n: int = 30) -> List[str]:\n",
    "    prompt = f\"\"\"\n",
    "You are a film-student recommender. Propose {n} movie titles that match this taste profile.\n",
    "\n",
    "Taste profile:\n",
    "{json.dumps(taste_profile, ensure_ascii=False)}\n",
    "\n",
    "Seed movies (do NOT include these):\n",
    "{seed_movies}\n",
    "\n",
    "Rules:\n",
    "- Choose films that match authorship/voice, narrative structure, themes, and tone.\n",
    "- Avoid spoilers.\n",
    "- Prefer interesting, non-obvious picks when possible.\n",
    "- Include a mix: 70% strong matches, 30% adjacent â€œstretchâ€ picks.\n",
    "\n",
    "Return ONLY JSON.\n",
    "\n",
    "{DIRECT_CANDIDATES_SCHEMA}\n",
    "\"\"\"\n",
    "    out = groq_chat(prompt, temperature=0.4)\n",
    "    data = extract_first_json(out)\n",
    "    titles = data.get(\"titles\", [])\n",
    "\n",
    "    if not isinstance(titles, list):\n",
    "        return []\n",
    "\n",
    "    # Dedupe preserving order\n",
    "    seen = set()\n",
    "    deduped = []\n",
    "    for t in titles:\n",
    "        if isinstance(t, str):\n",
    "            k = t.strip().lower()\n",
    "            if k and k not in seen:\n",
    "                seen.add(k)\n",
    "                deduped.append(t.strip())\n",
    "    return deduped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d611c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# 8) CURATOR (pick 5) + EXPLANATIONS (spoiler-free)\n",
    "# ============================================================\n",
    "\n",
    "CURATOR_SCHEMA = \"\"\"\n",
    "Return ONLY JSON:\n",
    "{\n",
    "  \"recommendations\": [\n",
    "    {\n",
    "      \"title\": string,\n",
    "      \"year\": string|null,\n",
    "      \"why_selected\": [strings]\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "def curate_five_movies(taste_profile: Dict[str, Any], candidate_pool: List[str], seed_movies: List[str]) -> Dict[str, Any]:\n",
    "    prompt = f\"\"\"\n",
    "You are a film student curator. Select 5 films for the viewer.\n",
    "\n",
    "Taste profile:\n",
    "{json.dumps(taste_profile, ensure_ascii=False)}\n",
    "\n",
    "Seed movies (do NOT recommend these):\n",
    "{seed_movies}\n",
    "\n",
    "Candidate pool:\n",
    "{candidate_pool[:120]}\n",
    "\n",
    "Rules:\n",
    "- Choose 5 films that best match the taste profile.\n",
    "- No ranking, just 5 picks.\n",
    "- Keep reasoning spoiler-free: craft, tone, themes, narrative style.\n",
    "- Avoid repeating the same explanation.\n",
    "\n",
    "{CURATOR_SCHEMA}\n",
    "\n",
    "ONLY output JSON.\n",
    "\"\"\"\n",
    "    out = groq_chat(prompt, temperature=0.2)\n",
    "    return extract_first_json(out)\n",
    "\n",
    "EXPLAIN_SCHEMA = \"\"\"\n",
    "Return ONLY JSON:\n",
    "{\n",
    "  \"cards\": [\n",
    "    {\n",
    "      \"title\": string,\n",
    "      \"year\": string|null,\n",
    "      \"why_this_fits\": [strings],   // exactly 3 bullets\n",
    "      \"watch_for\": string\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "def write_explanations(taste_profile: Dict[str, Any], curated: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    prompt = f\"\"\"\n",
    "Write spoiler-free recommendation cards.\n",
    "\n",
    "Taste profile:\n",
    "{json.dumps(taste_profile, ensure_ascii=False)}\n",
    "\n",
    "Selected movies:\n",
    "{json.dumps(curated, ensure_ascii=False)}\n",
    "\n",
    "Rules:\n",
    "- No plot spoilers, no twist mention, no ending description.\n",
    "- Explain via: authorship/voice, narrative architecture, themes/subtext, style/tone.\n",
    "- Each card should feel distinct and specific.\n",
    "- Use exactly 3 bullets for why_this_fits.\n",
    "\n",
    "{EXPLAIN_SCHEMA}\n",
    "\n",
    "ONLY output JSON.\n",
    "\"\"\"\n",
    "    out = groq_chat(prompt, temperature=0.3)\n",
    "    return extract_first_json(out)\n",
    "\n",
    "def print_recommendations(taste_profile: Dict[str, Any], final_cards: Dict[str, Any]):\n",
    "    print(\"\\n\" + \"=\"*90)\n",
    "    print(\"YOUR CINEMATIC TASTE (film-student summary)\")\n",
    "    print(\"=\"*90)\n",
    "    print((taste_profile.get(\"taste_summary\", \"\") or \"\").strip())\n",
    "\n",
    "    core = taste_profile.get(\"core_signals\", []) or []\n",
    "    if core:\n",
    "        print(\"\\nCore signals:\")\n",
    "        for s in core[:8]:\n",
    "            print(\" -\", s)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*90)\n",
    "    print(\"RECOMMENDATIONS (spoiler-free)\")\n",
    "    print(\"=\"*90)\n",
    "\n",
    "    cards = final_cards.get(\"cards\", []) or []\n",
    "    for i, c in enumerate(cards, start=1):\n",
    "        title = c.get(\"title\", \"\")\n",
    "        year = c.get(\"year\")\n",
    "        header = f\"{i}. {title}\" + (f\" ({year})\" if year else \"\")\n",
    "        print(\"\\n\" + header)\n",
    "        print(\"-\" * len(header))\n",
    "\n",
    "        for b in (c.get(\"why_this_fits\", []) or [])[:3]:\n",
    "            print(\" â€¢\", b)\n",
    "\n",
    "        wf = (c.get(\"watch_for\", \"\") or \"\").strip()\n",
    "        if wf:\n",
    "            print(\"   Watch for:\", wf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd3889de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŽ¬ Researching: The Pitt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 1/5 [00:00<00:02,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parse_url_list failed: unterminated string literal (detected at line 4) (<unknown>, line 4)\n",
      "raw sample: []\n",
      "(Note: I couldn't find any information on a movie called \"The Pitt\". If you could provide more context or details, I'd be happy to help.)\n",
      "\n",
      "However, I found that \"The Pitt\" might be a reference to a location in the Fallout 3 game, or a 2009 TV movie called \"The Pit\". If you're looking for information on the TV movie, here are some URLs:\n",
      "\n",
      "['https://en.wikipedia.org/wiki/The_Pit_(2009_film)', \n",
      "'ht\n",
      "URLs found: 0\n",
      "\n",
      "ðŸŽ¬ Researching: Industry\n",
      "URLs found: 4\n",
      " - https://en.wikipedia.org/wiki/Industry_(TV_series)\n",
      " - https://www.theatlantic.com/culture/archive/2020/11/hbo-industry-review/617103/\n",
      " - https://www.vulture.com/article/industry-hbo-review.html\n",
      "Scrape error: https://www.theatlantic.com/culture/archive/2020/11/hbo-industry-review/617103/ Website Not Supported: Failed to scrape. We apologize for the inconvenience but we do not support this site. If you are part of an enterprise and want to have a further conversation about this, please fill out our intake form here: https://fk4bvu0n5qp.typeform.com/to/Ej6oydlg - No additional error details provided.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:02<00:04,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Research length: 2814\n",
      "\n",
      "ðŸŽ¬ Researching: Bridgerton\n",
      "URLs found: 5\n",
      " - https://en.wikipedia.org/wiki/Bridgerton\n",
      " - https://www.vulture.com/article/bridgerton-netflix-review.html\n",
      " - https://www.theatlantic.com/culture/archive/2021/01/bridgerton-netflix-review/617627/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:04<00:03,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrape error: https://www.theatlantic.com/culture/archive/2021/01/bridgerton-netflix-review/617627/ Website Not Supported: Failed to scrape. We apologize for the inconvenience but we do not support this site. If you are part of an enterprise and want to have a further conversation about this, please fill out our intake form here: https://fk4bvu0n5qp.typeform.com/to/Ej6oydlg - No additional error details provided.\n",
      "Research length: 2810\n",
      "\n",
      "ðŸŽ¬ Researching: Heated Rivalry\n",
      "URLs found: 5\n",
      " - https://en.wikipedia.org/wiki/Heated_Rivalry\n",
      " - https://www.rogerebert.com/reviews/heated-rivalry-2022\n",
      " - https://www.theguardian.com/film/2022/jun/15/heated-rivalry-review\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:06<00:01,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Research length: 5527\n",
      "\n",
      "ðŸŽ¬ Researching: Hacks\n",
      "URLs found: 5\n",
      " - https://en.wikipedia.org/wiki/Hacks_(TV_series)\n",
      " - https://www.vulture.com/article/hacks-hbo-max-review.html\n",
      " - https://www.theatlantic.com/culture/archive/2021/05/hacks-hbo-max-jean-smart/618815/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:09<00:00,  1.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrape error: https://www.theatlantic.com/culture/archive/2021/05/hacks-hbo-max-jean-smart/618815/ Website Not Supported: Failed to scrape. We apologize for the inconvenience but we do not support this site. If you are part of an enterprise and want to have a further conversation about this, please fill out our intake form here: https://fk4bvu0n5qp.typeform.com/to/Ej6oydlg - No additional error details provided.\n",
      "Research length: 2812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Skipping The Pitt: not enough research text (0 chars)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:04<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search query: movies like Industry and Hacks \"character-driven narrative\" \"dark humor\" \"naturalistic performances\" \"ensemble cast\" \"fast-paced editing\" -\"overly stylized realism\" -\"broad humor\" -\"theatrical performances\"\n",
      "Candidate pool: 29\n",
      "Candidate sample: ['The Wolf of Wall Street', 'Nightcrawler', 'American Psycho', 'The Big Short', 'Boiler Room', 'Enron: The Smartest Guys in the Room', 'The Informant!', 'Match Point', 'The Departed', 'Gone Girl', 'Shutter Island', 'The Game', 'Election', 'The Player', 'Mulholland Drive', 'Blue Velvet', 'The Master', 'There Will Be Blood', \"There's Something About Mary\", 'Eternal Sunshine of the Spotless Mind']\n",
      "\n",
      "==========================================================================================\n",
      "YOUR CINEMATIC TASTE (film-student summary)\n",
      "==========================================================================================\n",
      "The viewer enjoys complex, character-driven stories with a mix of dark humor, psychological dread, and naturalistic performances, often exploring themes of ambition, power dynamics, and identity.\n",
      "\n",
      "Core signals:\n",
      " - character-driven\n",
      " - dark humor\n",
      " - psychological dread\n",
      " - naturalistic performances\n",
      " - ambition\n",
      " - power dynamics\n",
      " - identity\n",
      "\n",
      "==========================================================================================\n",
      "RECOMMENDATIONS (spoiler-free)\n",
      "==========================================================================================\n",
      "\n",
      "1. Nightcrawler (2014)\n",
      "----------------------\n",
      " â€¢ This film's narrative is driven by a complex, darkly comedic character study that explores the blurred lines between ambition and obsession.\n",
      " â€¢ The naturalistic performances and intimate cinematography create a sense of realism, drawing the viewer into the protagonist's unsettling world.\n",
      " â€¢ The movie's tone, which balances dark humor with psychological dread, aligns with your preference for thought-provoking, character-driven stories.\n",
      "   Watch for: A scathing critique of modern society, wrapped in a bundle of dark humor and psychological tension.\n",
      "\n",
      "2. The Informant! (2009)\n",
      "------------------------\n",
      " â€¢ The film's complex character study, led by a strong central performance, delves into themes of identity, ambition, and the blurred lines between truth and deception.\n",
      " â€¢ The mix of dark humor and psychological dread creates a sense of unease, keeping the viewer engaged and invested in the story.\n",
      " â€¢ The naturalistic performances and fast-paced editing contribute to a sense of realism, making the film's exploration of corporate greed and personal identity feel both timely and timeless.\n",
      "   Watch for: A nuanced, character-driven exploration of the human condition, with a healthy dose of dark humor and satire.\n",
      "\n",
      "3. American Psycho (2000)\n",
      "-------------------------\n",
      " â€¢ This film's dark humor and psychological dread are expertly woven together, creating a sense of unease that propels the viewer through the story.\n",
      " â€¢ The naturalistic performances, particularly from the lead, bring a sense of depth and complexity to the characters, making their actions feel both believable and terrifying.\n",
      " â€¢ The movie's exploration of identity, power dynamics, and social status, set against the backdrop of 1980s excess, feels both a commentary on its time and a timeless critique of societal values.\n",
      "   Watch for: A satirical, psychological thriller that uses dark humor to explore the emptiness and superficiality of modern life.\n",
      "\n",
      "4. Burn After Reading (2008)\n",
      "----------------------------\n",
      " â€¢ The film's ensemble cast and fast-paced editing create a sense of energy and tension, drawing the viewer into a complex web of relationships and motivations.\n",
      " â€¢ The mix of dark humor and psychological tension keeps the viewer on their toes, as the story navigates a complex exploration of ambition, identity, and power dynamics.\n",
      " â€¢ The naturalistic performances and intimate cinematography bring a sense of realism to the story, making the characters' flaws and mistakes feel both relatable and cringe-worthy.\n",
      "   Watch for: A darkly comedic, character-driven exploration of human nature, with a focus on the complexities and absurdities of modern life.\n",
      "\n",
      "5. The Master (2012)\n",
      "--------------------\n",
      " â€¢ The film's character-driven narrative, led by strong central performances, delves into themes of identity, power dynamics, and the search for meaning in a post-war world.\n",
      " â€¢ The naturalistic performances and intimate cinematography create a sense of realism, drawing the viewer into the complex, often fraught relationships between the characters.\n",
      " â€¢ The movie's tone, which balances psychological dread with a sense of introspective calm, aligns with your preference for thought-provoking, character-driven stories that explore the human condition.\n",
      "   Watch for: A nuanced, character-driven exploration of the human condition, with a focus on the complexities and mysteries of the human experience.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 9) RUN THE FULL MVP\n",
    "# ============================================================\n",
    "\n",
    "seed_movies = [\n",
    "    \"The Pitt\",\n",
    "    \"Industry\",\n",
    "    \"Bridgerton\",\n",
    "    \"Heated Rivalry\",\n",
    "    \"Hacks\"\n",
    "]\n",
    "\n",
    "# 1) Research seed movies\n",
    "research_data = research_movies(seed_movies, max_pages_per_movie=3)\n",
    "\n",
    "# 2) Fingerprint seeds\n",
    "seed_fingerprints = fingerprint_seed_movies(seed_movies, research_data)\n",
    "\n",
    "# 3) Taste profile\n",
    "taste = taste_profiler(seed_fingerprints)\n",
    "search_query = build_search_query(taste)\n",
    "print(\"\\nSearch query:\", search_query)\n",
    "\n",
    "# 4) Candidate pool (Groq-only)\n",
    "candidate_pool = propose_candidates_directly(taste, seed_movies, n=30)\n",
    "print(\"Candidate pool:\", len(candidate_pool))\n",
    "print(\"Candidate sample:\", candidate_pool[:20])\n",
    "\n",
    "# 5) Curate 5 + explanations\n",
    "curated = curate_five_movies(taste, candidate_pool, seed_movies)\n",
    "final_cards = write_explanations(taste, curated)\n",
    "\n",
    "# 6) Print\n",
    "print_recommendations(taste, final_cards)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
